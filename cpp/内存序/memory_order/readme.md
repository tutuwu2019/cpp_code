# readme

> 多线程的场景问题核心是多线程如何顺利的完成共享资源的顺序(时间序)共享。

共享资源，由普通的资源转变为原子型，保证操作的原子性(即具体参考事务)
然后原子型的顺序，引入的内存序，核心思想是 happen-before

## 内存排序
内存排序是指CPU访问主存时的顺序。可以时编译器在编译时产生，也可以是CPU在运行时产生。反映了内存操作重排序，乱序执行，从而充分利用不同内存的总线带宽。

> 现代处理器大都时乱序执行。因此需要内存屏障以确保多线程的同步。


- 编译时内存排序：这些内存屏障阻止编译器在编译时乱序指令，但在运行时无效
- 运行时内存排序：happens-before 按照程序的代码序执行。 synchronized-with 不同线程间，对于同一个原子操作，需要同步关系，store() 操作一定要先于 load(),也就是说对于一个原子变量x，先写，然后读x 是一个同步的操作

>> 运行时内存排序，重点是"同步"语义的解释，1.对于单个原子变量。2.多线程同一个原子操作。





## memory_orderxxx

- memory_order_relaxed 宽松操作：对其他读取或写入操作没有施加同步或者顺序约束，仅保证此操作的原子性
- memory_order_acquire 使用此内存顺序的加载操作会对受影响的内存位置执行获取操作：当前线程中的任何读取或写入操作都不能在此操作之前重新排序。其他线程中释放同一原子变量的所有写入操作在当前线程中都市可见的。
- memory_order_release 按照这种内存顺序的内存操作会执行释放操作：在此存储操作之后，当前线程中的任何读取或写入操作都不能重新操作。当前线程中的所有写入操作对于获取同一原子变量的其他线程都是可见的，并且对于依赖于该原子变量的写入操作，对于使用同一原子变量的其他线程也是可见的。
- memory_order_acq_rel 在这种内存顺序下，读-修改-写操作既是获取操作又是释放操作。当前线程中的任何内存读取或写入操作都不能在加载之前或之后重新排序。其他线程中释放同一原子变量的所有写入操作都发生在修改操作之前，而其他线程中获取同一原子变量的修改操作也同样可见。
- memory_order_seq_cst 按照这种内存顺序，加载操作执行 获取操作，存储操作执行 释放操作， 读-修改-写操作同时执行获取操作和释放操作，此外还存在一个总顺序，其中所有线程都按相同的顺序观察所有修改


## 同步方式分析

我们通常比较两种同步方式：原子操作(使用内存顺序)和锁(如互斥锁)。这里我们分析性能开销，并考虑使用非原子操作+锁 与原子操作(使用 release/acquire) 的比对

假设场景：多线程共享数据的读写同步
1. 使用锁(互斥锁)
    - 锁的开销
      - 锁的获取和释放操作，可能涉及原子操作和系统调用(如果竞争激烈，可能陷入内核)
      - 锁的争用会导致线程阻塞和上下文切换
      - 锁保护下的非原子操作可以按普通顺序执行，编译器可以优化(但不会跨锁重排)
2. 使用原子操作(配合合适的内存顺序)
- 开销包括
  - 原子操作本身(如原子加载、存储、交换等)通常比非原子操作慢，因为需要保证操作的原子性，可能使用缓存锁或总线锁
  - 内存屏障限制重排，可能影响编译器和CPU优化
  - 无锁编程可以减少阻塞，但可能需要更复杂的设计，并且再高争用情况下可能因为重试(CAS失败)导致开销


详细对比：
锁的开销：
- 无竞争时，锁的开销主要是两次原子操作(获取和释放锁)加上一些屏障。在无竞争时可能只需要用户空间的原子操作，而不需要系统调用。
- 有锁竞争时，当锁被占用时，其他线程会阻塞，可能被操作系统挂起，导致上下文切换和调度开销

原子操作的开销：
- 原子操作本身是硬件支持的，通常通过缓存一致性协议(如MESI)来保证原子性，不一定会锁总线。但是原子操作可能会影响缓存行，导致缓存一致性流量增加。
- 内存屏障：release 和 acquire 屏障在大多数架构上(如x86上)是相对廉价的，因为x86本身有较强的内存模型(除了 StoreLoad屏障)。但在弱内存模型架构(ARM)上，屏障可能需要现实指令，开销较大。

性能分析：
- 低争用情况：原子操作通常比锁快，因为原子操作不需要进入内核，也没有线程阻塞和切换的开销。但是，如果原子操作在一个循环中不断重试(例如自旋锁)，可能会消耗CPU资源。
- 高争用情况：原子操作(特别是CAS)在高争用下可能导致大量重试，每个线程都在竞争同一个内存地址，导致缓存行在核心之间频繁移动(缓存行乒乓)，这会严重影响性能。而锁在高争用下会将线程阻塞并挂起，从而减少CPU资源的浪费(但吞吐量可能下降)
使用非原子操作 + 锁 vs 原子操作 (顺序同步)

- 锁保护非原子操作时，临界区内的操作可以是非原子的，因此可以有较好的局部性和编译器优化。但是对锁的粒度较大时，可能会限制并行度。
- 原子操作允许更细粒度的同步，但编程复杂，容易出错，并且对于复杂操作(如多个变量的更新)可能需要使用多个原子操作或CAS 循环，这可能会比锁更慢。

总结：
- 如果共享数据的操作很简单(如单个变量的读写)，原子操作通常比锁性能更好。
- 如果操作复杂(如涉及多个变量，或者需要多个步骤)，使用锁可能更简单，且性能可能更好(因为锁可以一次保护所有操作，而原子操作可能需要多个原子操作或循环CAS，并且每个原子操作都可能引起缓存行乒乓)额。
- 在高争用情况下，锁可以通过阻塞线程来减少CPU消耗，而原子操作的自旋可能会浪费CPU周期。但是，如果临界区很短，自旋锁(或原子操作)可能更合适，因为阻塞和唤醒线程的开销可能比自旋更大。

实际应用中，需要更具具体情况(争用程度、临界区大小、硬件架构)来选择。


总的来说，c++11以上的版本提供了原子操作和内存顺序允许我们来实现无锁数据结构，对于模块简单的部分可以较好的设计并实现无锁数据结构。但是对于整个项目架构或者复杂的场景，正确的实现无锁结构非常困难，而使用锁则相对简单。在性能要求极高且争用较低的情况下，无锁编程可能带来性能的提升，但通常不建议除非确实需要。



一些性能测试数据

```text
./performance_test_01 12 10000000
线程数: 12, 每线程递增次数: 10000000, 预期最终值: 120000000

=== 测试原子无锁版 ===
原子无锁版 (std::atomic) 时间: 1.87508 秒
最终计数: 120000000 (正确性: OK)

=== 测试互斥锁版 ===
互斥锁版 (std::mutex) 时间: 1.81034 秒
最终计数: 120000000 (正确性: OK)

./performance_test_01 12 100000000
线程数: 12, 每线程递增次数: 100000000, 预期最终值: 1200000000

=== 测试原子无锁版 ===
原子无锁版 (std::atomic) 时间: 18.6059 秒
最终计数: 1200000000 (正确性: OK)

=== 测试互斥锁版 ===
互斥锁版 (std::mutex) 时间: 18.8568 秒
最终计数: 1200000000 (正确性: OK)

 ./performance_test_01 24 100000000
线程数: 24, 每线程递增次数: 100000000, 预期最终值: 2400000000

=== 测试原子无锁版 ===
原子无锁版 (std::atomic) 时间: 38.224 秒
最终计数: 2400000000 (正确性: OK)

=== 测试互斥锁版 ===
互斥锁版 (std::mutex) 时间: 43.147 秒
最终计数: 2400000000 (正确性: OK)

./performance_test_01 32 100000000
线程数: 32, 每线程递增次数: 100000000, 预期最终值: 3200000000

=== 测试原子无锁版 ===
原子无锁版 (std::atomic) 时间: 52.0408 秒
最终计数: 3200000000 (正确性: OK)

=== 测试互斥锁版 ===
互斥锁版 (std::mutex) 时间: 60.2675 秒
最终计数: 3200000000 (正确性: OK)
```


## 参考文档

[内存排序](https://colobu.com/atomics/3_Memory_Ordering.html)   
[指令重排序与内存屏障](https://zhuanlan.zhihu.com/p/359093580)
